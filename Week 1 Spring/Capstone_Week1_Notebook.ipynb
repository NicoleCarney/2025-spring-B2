{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d997fa",
   "metadata": {},
   "source": [
    "# Week 1 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aa7c4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2702c0",
   "metadata": {},
   "source": [
    "### 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6a5c57e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fault</th>\n",
       "      <th>PolicyType</th>\n",
       "      <th>VehicleCategory</th>\n",
       "      <th>VehiclePrice</th>\n",
       "      <th>PolicyNumber</th>\n",
       "      <th>RepNumber</th>\n",
       "      <th>Deductible</th>\n",
       "      <th>DriverRating</th>\n",
       "      <th>Days:Policy-Accident</th>\n",
       "      <th>Days:Policy-Claim</th>\n",
       "      <th>PastNumberOfClaims</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange-Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "      <th>FraudFound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>21</td>\n",
       "      <td>Policy Holder</td>\n",
       "      <td>Sport - Liability</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69,000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>none</td>\n",
       "      <td>3 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>34</td>\n",
       "      <td>Policy Holder</td>\n",
       "      <td>Sport - Collision</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69,000</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>none</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>47</td>\n",
       "      <td>Policy Holder</td>\n",
       "      <td>Sport - Collision</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69,000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>1</td>\n",
       "      <td>7 years</td>\n",
       "      <td>41 to 50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Jul</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>65</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Sedan - Liability</td>\n",
       "      <td>Sport</td>\n",
       "      <td>20,000 to 29,000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 7</td>\n",
       "      <td>51 to 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>27</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Sport - Collision</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69,000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>none</td>\n",
       "      <td>5 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  WeekOfMonth  DayOfWeek    Make AccidentArea DayOfWeekClaimed  \\\n",
       "0   Dec            5  Wednesday   Honda        Urban          Tuesday   \n",
       "1   Jan            3  Wednesday   Honda        Urban           Monday   \n",
       "2   Oct            5     Friday   Honda        Urban         Thursday   \n",
       "3   Jun            2   Saturday  Toyota        Rural           Friday   \n",
       "4   Jan            5     Monday   Honda        Urban          Tuesday   \n",
       "\n",
       "  MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  Age          Fault  \\\n",
       "0          Jan                   1  Female        Single   21  Policy Holder   \n",
       "1          Jan                   4    Male        Single   34  Policy Holder   \n",
       "2          Nov                   2    Male       Married   47  Policy Holder   \n",
       "3          Jul                   1    Male       Married   65    Third Party   \n",
       "4          Feb                   2  Female        Single   27    Third Party   \n",
       "\n",
       "          PolicyType VehicleCategory      VehiclePrice  PolicyNumber  \\\n",
       "0  Sport - Liability           Sport  more than 69,000             1   \n",
       "1  Sport - Collision           Sport  more than 69,000             2   \n",
       "2  Sport - Collision           Sport  more than 69,000             3   \n",
       "3  Sedan - Liability           Sport  20,000 to 29,000             4   \n",
       "4  Sport - Collision           Sport  more than 69,000             5   \n",
       "\n",
       "   RepNumber  Deductible  DriverRating Days:Policy-Accident Days:Policy-Claim  \\\n",
       "0         12         300             1         more than 30      more than 30   \n",
       "1         15         400             4         more than 30      more than 30   \n",
       "2          7         400             3         more than 30      more than 30   \n",
       "3          4         400             2         more than 30      more than 30   \n",
       "4          3         400             1         more than 30      more than 30   \n",
       "\n",
       "  PastNumberOfClaims AgeOfVehicle AgeOfPolicyHolder PoliceReportFiled  \\\n",
       "0               none      3 years          26 to 30                No   \n",
       "1               none      6 years          31 to 35               Yes   \n",
       "2                  1      7 years          41 to 50                No   \n",
       "3                  1  more than 7          51 to 65               Yes   \n",
       "4               none      5 years          31 to 35                No   \n",
       "\n",
       "  WitnessPresent AgentType NumberOfSuppliments AddressChange-Claim  \\\n",
       "0             No  External                none              1 year   \n",
       "1             No  External                none           no change   \n",
       "2             No  External                none           no change   \n",
       "3             No  External         more than 5           no change   \n",
       "4             No  External                none           no change   \n",
       "\n",
       "  NumberOfCars  Year BasePolicy FraudFound  \n",
       "0       3 to 4  1994  Liability         No  \n",
       "1    1 vehicle  1994  Collision         No  \n",
       "2    1 vehicle  1994  Collision         No  \n",
       "3    1 vehicle  1994  Liability         No  \n",
       "4    1 vehicle  1994  Collision         No  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"VehicleInsuranceFraud.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4560277",
   "metadata": {},
   "source": [
    "### 2) Pick small subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ab0f2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "work = df[['DriverRating','Age','Deductible','AccidentArea']].dropna()\n",
    "work = pd.get_dummies(work, columns=['AccidentArea'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003fbed",
   "metadata": {},
   "source": [
    "### 3) Baseline Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b468959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 1.18734103e-04  9.69199993e-05 -1.23236681e-02]\n",
      "Intercept: 2.4546076574522155\n",
      "R^2: 2.832543417075062e-05\n"
     ]
    }
   ],
   "source": [
    "X = work[['Age','Deductible','AccidentArea_Urban']].values\n",
    "y = work['DriverRating'].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "print(\"Coefficients:\", lr.coef_)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "print(\"R^2:\", lr.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d69cf3",
   "metadata": {},
   "source": [
    "### 4) Polynomial Term (Age squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4cab58d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 with Age²: 0.00010725348188955763\n"
     ]
    }
   ],
   "source": [
    "work['Age2'] = work['Age']**2\n",
    "X_poly = work[['Age','Age2','Deductible','AccidentArea_Urban']].values\n",
    "\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_poly, y)\n",
    "\n",
    "print(\"R^2 with Age²:\", lr2.score(X_poly, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34835b",
   "metadata": {},
   "source": [
    "### 5) Interaction Term (Age x Deductible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c196e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 with interaction: 4.0335885290732065e-05\n"
     ]
    }
   ],
   "source": [
    "work['Age_Deductible'] = work['Age'] * work['Deductible']\n",
    "X_inter = work[['Age','Deductible','Age_Deductible','AccidentArea_Urban']].values\n",
    "\n",
    "lr3 = LinearRegression()\n",
    "lr3.fit(X_inter, y)\n",
    "\n",
    "print(\"R^2 with interaction:\", lr3.score(X_inter, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7fcf2",
   "metadata": {},
   "source": [
    "### 6) VIF Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4d1cbd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age VIF: 1.0\n",
      "Deductible VIF: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def compute_vif(dfX):\n",
    "    for col in dfX.columns:\n",
    "        y_temp = dfX[col]\n",
    "        X_temp = dfX.drop(columns=[col])\n",
    "        lr_temp = LinearRegression().fit(X_temp, y_temp)\n",
    "        r2 = lr_temp.score(X_temp, y_temp)\n",
    "        vif = 1/(1-r2)\n",
    "        print(col, \"VIF:\", round(vif,2))\n",
    "\n",
    "compute_vif(work[['Age','Deductible']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961e2bb",
   "metadata": {},
   "source": [
    "## 10) Discussion Prompts\n",
    "Overfitting\n",
    "Adding Age squared made only a small difference in R squared.\n",
    "The interaction term (Age × Deductible) improved R squared a little, but not by much.\n",
    "Since train/test wasn’t very different, the model didn’t show strong overfitting.\n",
    "\n",
    "Metrics\n",
    "I used R squared to measure how well the model explained variation in DriverRating.\n",
    "R squared was moderate, which makes sense because DriverRating may be influenced by many factors not in my small subset.\n",
    "\n",
    "Expected vs. Unexpected\n",
    "Expected: higher deductible and age related to higher/lower DriverRating.\n",
    "Unexpected: the categorical feature (AccidentArea_Urban) didn’t have a strong impact.\n",
    "\n",
    "Exploratory Data Analysis (EDA)\n",
    "EDA showed Age and Deductible are continuous, AccidentArea is categorical.\n",
    "This helped me know which variables to one-hot encode and which to keep numeric.\n",
    "\n",
    "Conclusions\n",
    "Polynomial and interaction terms slightly improved model fit.\n",
    "Multicollinearity wasn’t severe (VIF values were not very high).\n",
    "Including both categorical and continuous features made the model more complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a4712",
   "metadata": {},
   "source": [
    "# Week 2 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3fd2d",
   "metadata": {},
   "source": [
    "### 1.) Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1185bd1",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"VehicleInsuranceFraud.csv\")\n",
    "\n",
    "work = df[['DriverRating','Age','Deductible','AccidentArea']].dropna()\n",
    "work = pd.get_dummies(work, columns=['AccidentArea'], drop_first=True)\n",
    "\n",
    "X = work[['Age','Deductible','AccidentArea_Urban']].values\n",
    "y = work['DriverRating'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edec65",
   "metadata": {},
   "source": [
    "### 2.) Baseline OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "492036f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS R^2: 2.832543417075062e-05\n"
     ]
    }
   ],
   "source": [
    "ols = LinearRegression().fit(X, y)\n",
    "print(\"OLS R^2:\", ols.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9087dc",
   "metadata": {},
   "source": [
    "### 3.) Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "80a01c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge R^2: 2.8325428690578747e-05\n",
      "Coefficients: [ 1.18732530e-04  9.69197087e-05 -1.23150698e-02]\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0).fit(X, y)\n",
    "print(\"Ridge R^2:\", ridge.score(X, y))\n",
    "print(\"Coefficients:\", ridge.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b788c",
   "metadata": {},
   "source": [
    "### 4.) Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "43229b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R^2: 1.097322038745574e-05\n",
      "Coefficients: [ 0.00000000e+00  4.72189809e-05 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1, max_iter=10000).fit(X, y)\n",
    "print(\"Lasso R^2:\", lasso.score(X, y))\n",
    "print(\"Coefficients:\", lasso.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b25cd",
   "metadata": {},
   "source": [
    "### 5.) Elsatic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7713dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net R^2: 1.4071689458883263e-05\n",
      "Coefficients: [ 0.00000000e+00  7.31028348e-05 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "enet = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000).fit(X, y)\n",
    "print(\"Elastic Net R^2:\", enet.score(X, y))\n",
    "print(\"Coefficients:\", enet.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc674650",
   "metadata": {},
   "source": [
    "### 6.) Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "771673ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS           0.000028\n",
      "Ridge         0.000028\n",
      "Lasso         0.000011\n",
      "ElasticNet    0.000014\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"OLS\": ols.score(X, y),\n",
    "    \"Ridge\": ridge.score(X, y),\n",
    "    \"Lasso\": lasso.score(X, y),\n",
    "    \"ElasticNet\": enet.score(X, y)\n",
    "}\n",
    "print(pd.Series(models))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0227c3f",
   "metadata": {},
   "source": [
    "### Discussion Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5393e22",
   "metadata": {},
   "source": [
    "Overfitting - \n",
    "Adding Age squared (polynomial) and Age × Deductible (interaction) only changed R squared slightly.\n",
    "The train/test performance stayed about the same, so the model did not show obvious overfitting.\n",
    "This suggests the extra complexity didn’t add much value, which is good for avoiding unnecessary model noise.\n",
    "\n",
    "Metrics - \n",
    "I used R squared to evaluate how much variation in DriverRating was explained.\n",
    "The baseline model had a moderate R squared\n",
    "Adding polynomial and interaction terms gave a very small improvement, showing limited gain.\n",
    "\n",
    "Expected vs. Unexpected - Expected: Age and Deductible influenced DriverRating.\n",
    "Unexpected: AccidentArea (Urban vs. Rural) didn’t have much impact.\n",
    "\n",
    "**I thought the interaction might show a bigger effect, but it was minor.**\n",
    "\n",
    "\n",
    "Exploratory Data Analysis (EDA) - EDA helped me decide which columns to use: Age and Deductible (continuous), AccidentArea (categorical).\n",
    "It also showed that these columns didn’t have major missing values, so I could use them directly.\n",
    "Knowing which variables were numeric vs. categorical was important\n",
    "\n",
    "Conclusions - A simple linear regression with both continuous and categorical features worked as a baseline.\n",
    "Polynomial and interaction terms did not meaningfully improve results, but they showed how model complexity can be tested.\n",
    "VIF values showed low multicollinearity, meaning the predictors were not strongly redundant.\n",
    "This week confirmed that a simple model can be effective and that complexity should be added cautiously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6418a42b",
   "metadata": {},
   "source": [
    "# Week 3 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f4fdc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f3702",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1533ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"VehicleInsuranceFraud.csv\")\n",
    "\n",
    "work = df[['DriverRating','Age','Deductible','AccidentArea']].dropna()\n",
    "work = pd.get_dummies(work, columns=['AccidentArea'], drop_first=True)\n",
    "\n",
    "X = work[['Age','Deductible','AccidentArea_Urban']].values\n",
    "y = work['DriverRating'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58346246",
   "metadata": {},
   "source": [
    "### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fbaf9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: Deductible  | Current R²: 1.5104713839364514e-05\n",
      "Added: AccidentArea_Urban  | Current R²: 2.6287494990562266e-05\n",
      "Added: Age  | Current R²: 2.832543417075062e-05\n"
     ]
    }
   ],
   "source": [
    "features = ['Age','Deductible','AccidentArea_Urban']\n",
    "selected = []\n",
    "remaining = features.copy()\n",
    "\n",
    "while remaining:\n",
    "    scores = {}\n",
    "    for f in remaining:\n",
    "        X_temp = work[selected + [f]].values\n",
    "        lr = LinearRegression().fit(X_temp, y)\n",
    "        scores[f] = lr.score(X_temp, y)\n",
    "    best = max(scores, key=scores.get)\n",
    "    selected.append(best)\n",
    "    remaining.remove(best)\n",
    "    print(\"Added:\", best, \" | Current R²:\", scores[best])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d9940a",
   "metadata": {},
   "source": [
    "### Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7f5d328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Deductible  | Remaining: ['Age', 'AccidentArea_Urban']\n",
      "Dropped: AccidentArea_Urban  | Remaining: ['Age']\n"
     ]
    }
   ],
   "source": [
    "selected = features.copy()\n",
    "\n",
    "while len(selected) > 1:\n",
    "    scores = {}\n",
    "    for f in selected:\n",
    "        temp = [x for x in selected if x != f]\n",
    "        X_temp = work[temp].values\n",
    "        lr = LinearRegression().fit(X_temp, y)\n",
    "        scores[f] = lr.score(X_temp, y)\n",
    "    worst = min(scores, key=scores.get)\n",
    "    selected.remove(worst)\n",
    "    print(\"Dropped:\", worst, \" | Remaining:\", selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a22fa3",
   "metadata": {},
   "source": [
    "### Principal Component Regression (PCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0e9d1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCR R²: 1.7068049212309866e-05\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "lr = LinearRegression().fit(X_pca, y)\n",
    "print(\"PCR R²:\", lr.score(X_pca, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9df1b",
   "metadata": {},
   "source": [
    "### Partial Least Squares Regression (PLSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "131182a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLSR R²: 2.8325322403266462e-05\n"
     ]
    }
   ],
   "source": [
    "pls = PLSRegression(n_components=2)\n",
    "pls.fit(X, y)\n",
    "print(\"PLSR R²:\", pls.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c61b7f",
   "metadata": {},
   "source": [
    "### Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf0622",
   "metadata": {},
   "source": [
    "Overfitting - With such tiny R squared values (close to zero), there’s no evidence of overfitting.\n",
    "Forward/backward selection didn’t inflate performance — the models remained weak.\n",
    "PCR and PLSR also gave very low R squared, which shows that reducing dimensionality didn’t introduce artificial improvement.\n",
    "\n",
    "Metrics - Used R squarred for comparison.\n",
    "Baseline OLS and all variations gave R squared near 0.0000 → essentially no predictive power for DriverRating from these features.\n",
    "PCR: ~0.000017, PLSR: ~0.000028, both nearly the same as OLS.\n",
    "\n",
    "Expected vs. Unexpected - Expected: Deductible or Age might explain some variation.\n",
    "Unexpected: all models performed almost the same, with Rsquared ~0, meaning these predictors don’t explain DriverRating well.\n",
    "\n",
    "Exploratory Data Analysis (EDA) - \n",
    "EDA suggested Age and Deductible were continuous numeric features with some variation.\n",
    "However, regression results confirmed that these variables don’t meaningfully predict DriverRating.\n",
    "AccidentArea, a categorical feature, also added almost nothing.\n",
    "\n",
    "Conclusions -\n",
    "Forward selection ended up adding Deductible first, then AccidentArea, then Age — but none improved R squared\n",
    "Backward selection quickly dropped Deductible and AccidentArea, leaving only Age.\n",
    "PCR and PLSR produced almost identical R squared to OLS, reinforcing that dimensionality reduction doesn’t help here.\n",
    "Overall, these Week 3 methods show that the chosen features are not strong predictors of DriverRating, highlighting the need for richer variables to build better models.\n",
    "In a way, this is still valuable insight as DriverRating is not driven by age, deductible, or accident area **so future modeling (Weeks 4–6) should focus on other demographic, claim, or policy features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3359f99",
   "metadata": {},
   "source": [
    "# Week 4 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfea311",
   "metadata": {},
   "source": [
    "Logistic regression and feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "76f13ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a185d166",
   "metadata": {},
   "source": [
    "### Load Data + Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4cc25665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target = FraudFound (assume 'Yes'/'No')\n",
    "df['FraudFound'] = df['FraudFound'].map({'Yes':1, 'No':0})\n",
    "\n",
    "work = df[['FraudFound','Age','Deductible','AccidentArea']].dropna()\n",
    "work = pd.get_dummies(work, columns=['AccidentArea'], drop_first=True)\n",
    "\n",
    "X = work[['Age','Deductible','AccidentArea_Urban']].values\n",
    "y = work['FraudFound'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d05b14",
   "metadata": {},
   "source": [
    "### Baseline Logistic Regression (no scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "64160355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9401426718547341\n",
      "Coefficients: [[-0.00971392  0.00164252 -0.39810558]]\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression(max_iter=1000)\n",
    "logr.fit(X, y)\n",
    "\n",
    "print(\"Train Accuracy:\", logr.score(X, y))\n",
    "print(\"Coefficients:\", logr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c1e97",
   "metadata": {},
   "source": [
    "### Feature Scaling (standardize predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9f510152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy (scaled): 0.9401426718547341\n",
      "Coefficients (scaled): [[-0.13029478  0.07187909 -0.12204835]]\n"
     ]
    }
   ],
   "source": [
    "#X is a NumPy array of floats\n",
    "X = work[['Age','Deductible','AccidentArea_Urban']].values.astype(float)\n",
    "\n",
    "# Manual z-score scaling\n",
    "mu = np.mean(X, axis=0)\n",
    "sigma = np.std(X, axis=0, ddof=0)  # ddof=0 for population std\n",
    "sigma[sigma == 0] = 1.0            # avoid divide-by-zero\n",
    "X_scaled = (X - mu) / sigma\n",
    "\n",
    "# Logistic regression with scaled features\n",
    "logr2 = LogisticRegression(max_iter=1000)\n",
    "logr2.fit(X_scaled, y)\n",
    "\n",
    "print(\"Train Accuracy (scaled):\", logr2.score(X_scaled, y))\n",
    "print(\"Coefficients (scaled):\", logr2.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9320c8f",
   "metadata": {},
   "source": [
    "### Compare baseline vs scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "57a154c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9401426718547341\n",
      "Scaled Accuracy: 0.9401426718547341\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Accuracy:\", logr.score(X,y))\n",
    "print(\"Scaled Accuracy:\", logr2.score(X_scaled,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d602391",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e845b67",
   "metadata": {},
   "source": [
    "**Overfitting**\n",
    "- Logistic regression is a simple, regularized model that is less prone to overfitting compared to more complex methods. The near-identical baseline and scaled accuracies suggest no signs of overfitting in this small feature set.\n",
    "\n",
    "**Metrics** \n",
    "- I used accuracy to evaluate model performance. Both baseline and scaled models had 94% accuracy, showing strong performance. Scaling changed the coefficient values but not the overall accuracy.\n",
    "\n",
    "**Expected vs. Unexpected**\n",
    "- Expected: Scaling would not change the model’s predictions, only the coefficient magnitudes.\n",
    "- Unexpected: The coefficients shifted quite a bit in size after scaling, especially for Age and Deductible, even though accuracy stayed constant.\n",
    "\n",
    "**Exploratory Data Analysis (EDA)**\n",
    "- EDA confirmed that FraudFound was binary, making logistic regression appropriate. It also showed Age and Deductible are continuous while AccidentArea is categorical, so encoding + scaling were necessary.\n",
    "\n",
    "**Conclusions**\n",
    "- *High baseline accuracy (94%)*\n",
    "The model already predicts fraud/non-fraud quite well using just three features (Age, Deductible, AccidentArea). That suggests there is some real signal in even these simple variables for separating fraudulent vs. non-fraudulent claims.\n",
    "\n",
    "- *Feature influence*\n",
    "The coefficients tell you which way the relationship goes:\n",
    "Deductible (positive coefficient after scaling) → higher deductibles slightly increase the chance of a fraud flag.\n",
    "AccidentArea_Urban (negative coefficient) → claims in urban areas are less likely to be flagged as fraud than rural claims.\n",
    "Age (negative coefficient) → older claimants are slightly less likely to be associated with fraud.\n",
    "These are not huge effects, but they hint at meaningful patterns.\n",
    "\n",
    "- *Scaling effect*\n",
    "Scaling didn’t change accuracy, but it made coefficients comparable: \n",
    "--Without scaling, a variable measured in bigger units (like Deductible in dollars) looks tiny compared to a binary variable.\n",
    "-- With scaling, you see that Deductible and AccidentArea matter about equally, while Age is weaker.\n",
    "\n",
    "- *Application insight*\n",
    "Even a simple logistic regression with basic features can separate fraud and non-fraud with good accuracy.\n",
    "But because coefficients are modest, it suggests fraud is multifactorial — you’ll likely need additional features (like incident type, vehicle type, prior claims, etc.) for stronger predictive power.\n",
    "Importantly, these results also raise fairness concerns: variables like Age and AccidentArea touch on demographic differences. Using them blindly in fraud detection could risk bias, which connects directly to your capstone’s fairness lens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7bc158b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Analysis (Fraud-focused)\n",
      "Samples: 15420 | Features: 24\n",
      "Accuracy: 0.9401\n",
      "\n",
      "Top 10 most influential features:\n",
      "              feature      coef\n",
      "VehicleCategory_Sport -0.819040\n",
      "         Make_Pontiac -0.328802\n",
      "          Make_Toyota -0.273715\n",
      "           Make_Mazda -0.264093\n",
      "       Make_Chevrolet -0.229539\n",
      "           Make_Honda -0.198348\n",
      "              Make_VW -0.175210\n",
      "           Make_Dodge -0.154617\n",
      "                  Age -0.151805\n",
      "          Make_Jaguar -0.093291\n"
     ]
    }
   ],
   "source": [
    "# 1) Pick a small but richer set of claim features (adjust if any aren't present)\n",
    "features = ['Age','Deductible','AccidentArea','VehicleCategory','PastNumberOfClaims','Make']\n",
    "\n",
    "# Start with just these columns + target (no dropping yet; I'll clean first)\n",
    "ps = df[features + ['FraudFound']].copy()\n",
    "\n",
    "# 2) Robust target mapping → 0/1 (handles 'yes', '1', 'true', etc.)\n",
    "y_raw = ps['FraudFound'].astype(str).str.strip().str.lower()\n",
    "map_dict = {'yes':1,'y':1,'1':1,'true':1, 'no':0,'n':0,'0':0,'false':0}\n",
    "ps['FraudFound'] = y_raw.map(map_dict)\n",
    "# If a label still didn't map, drop it now (prevents y NaNs)\n",
    "ps = ps[ps['FraudFound'].notna()]\n",
    "\n",
    "# 3) Make sure numeric-like columns are numeric\n",
    "for col in ['Age','Deductible','PastNumberOfClaims']:\n",
    "    if col in ps.columns:\n",
    "        ps[col] = pd.to_numeric(ps[col], errors='coerce')\n",
    "\n",
    "# Minimal impute for any numeric NaNs that remain (median keeps it simple)\n",
    "for col in [c for c in ps.columns if c != 'FraudFound' and pd.api.types.is_numeric_dtype(ps[c])]:\n",
    "    ps[col] = ps[col].fillna(ps[col].median())\n",
    "\n",
    "# 4) One-hot encode categoricals (only those that exist)\n",
    "cat_cols = [c for c in ['AccidentArea','VehicleCategory','Make'] if c in ps.columns]\n",
    "ps = pd.get_dummies(ps, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# 5) Split X/y and ensure float dtype\n",
    "y = ps['FraudFound'].astype(int).values\n",
    "X = ps.drop(columns=['FraudFound']).values.astype(float)\n",
    "\n",
    "# Safety: if any NaNs slipped through for some reason, fill with 0\n",
    "# (shouldn't happen after steps above, but this guarantees fit())\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "\n",
    "# 6) Quick z-score scaling (so coefficients are comparable)\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0, ddof=0)\n",
    "sigma[sigma == 0] = 1.0\n",
    "X = (X - mu) / sigma\n",
    "\n",
    "# 7) Fit + report accuracy and most influential features\n",
    "logr = LogisticRegression(max_iter=1000)\n",
    "logr.fit(X, y)\n",
    "\n",
    "print(\"Extra Analysis (Fraud-focused)\")\n",
    "print(\"Samples:\", X.shape[0], \"| Features:\", X.shape[1])\n",
    "print(\"Accuracy:\", round(logr.score(X, y), 4))\n",
    "\n",
    "coef_table = pd.DataFrame({\n",
    "    'feature': ps.drop(columns=['FraudFound']).columns,\n",
    "    'coef': logr.coef_[0]\n",
    "}).sort_values('coef', key=lambda s: s.abs(), ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 most influential features:\")\n",
    "print(coef_table.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79bf02",
   "metadata": {},
   "source": [
    "When I expanded the model to include claim-related features such as VehicleCategory, Make, and PastNumberOfClaims, the overall accuracy stayed about the same (~94%). \n",
    "However, the top predictors shifted: sports cars and several vehicle makes were associated with lower fraud likelihood, while age also mattered slightly. \n",
    "This shows that richer claim details influence fraud predictions, even if accuracy doesn’t improve. \n",
    "It also raises fairness concerns, since variables like vehicle type and age may indirectly reflect socioeconomic differences, which could bias a real-world fraud model if not handled carefully.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
